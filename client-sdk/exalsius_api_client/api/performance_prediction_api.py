# coding: utf-8

"""
exalsius API

The exalsius REST API enables programmatic access to GPU infrastructure management and orchestration capabilities. Access the API through the `exls` command-line tool or integrate it directly into your applications using standard HTTP requests. The API covers several areas: * **GPU Market Offers** Browse and compare GPU instance pricing across public cloud providers and hyperscalers. * **Operator Integration** Coordinates with the [exalsius-operator](https://github.com/exalsius/exalsius-operator) running in a management Kubernetes cluster to handle infrastructure provisioning and node lifecycle management. * **Node Management** Import cloud-provider instances or self-managed nodes (via SSH) into your node pool. Hardware characteristics of self-managed nodes are discovered automatically. * **Cluster Provisioning** Create and manage Kubernetes clusters on supported cloud providers or self-managed bare-metal infrastructure. * **Service Deployment** Deploy infrastructure services such as the NVIDIA GPU Operator, KubeRay, Flyte, or Kubeflow onto your clusters. * **Workspace Deployment** Provision application workloads including Jupyter Notebook servers, LLM inference services, and other compute workloads on your clusters.

The version of the OpenAPI document: 1.25.2
Contact: support@exalsius.ai
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501

from typing import Any, Dict, List, Optional, Tuple, Union

from pydantic import Field, StrictFloat, StrictInt, StrictStr, validate_call
from typing_extensions import Annotated

from exalsius_api_client.api_client import ApiClient, RequestSerialized
from exalsius_api_client.api_response import ApiResponse
from exalsius_api_client.models.performance_prediction_request import \
    PerformancePredictionRequest
from exalsius_api_client.models.performance_prediction_response import \
    PerformancePredictionResponse
from exalsius_api_client.rest import RESTResponseType


class PerformancePredictionApi:
    """NOTE: This class is auto generated by OpenAPI Generator
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    def __init__(self, api_client=None) -> None:
        if api_client is None:
            api_client = ApiClient.get_default()
        self.api_client = api_client

    @validate_call
    def get_performance_prediction(
        self,
        performance_prediction_request: PerformancePredictionRequest,
        _request_timeout: Union[
            None,
            Annotated[StrictFloat, Field(gt=0)],
            Tuple[
                Annotated[StrictFloat, Field(gt=0)], Annotated[StrictFloat, Field(gt=0)]
            ],
        ] = None,
        _request_auth: Optional[Dict[StrictStr, Any]] = None,
        _content_type: Optional[StrictStr] = None,
        _headers: Optional[Dict[StrictStr, Any]] = None,
        _host_index: Annotated[StrictInt, Field(ge=0, le=0)] = 0,
    ) -> PerformancePredictionResponse:
        """Get runtime performance predictions for a GPU-accelerated workload configuration

        **Get performance predictions for GPU-accelerated training workloads**  This endpoint returns predicted runtime and memory usage (VRAM) for a given training configuration. The predictions are provided per GPU type, allowing you to compare performance across different GPU models.  **Request Parameters:** - `model_name`: The machine learning model to train - `optimizer`: The optimization algorithm (adam or adamw) - `batch_size`: Number of samples processed per training step - `sequence_length`: Length of input sequences (tokens) - `accumulation_steps`: Number of gradient accumulation steps (use 1 for no accumulation)  **Response:** - `vram`: Predicted VRAM usage in GB, keyed by GPU type (e.g., \"A100\", \"H100\", \"RTX4090\") - `runtime`: Predicted runtime per training step in seconds, keyed by GPU type

        :param performance_prediction_request: (required)
        :type performance_prediction_request: PerformancePredictionRequest
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :type _request_timeout: int, tuple(int, int), optional
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the
                              authentication in the spec for a single request.
        :type _request_auth: dict, optional
        :param _content_type: force content-type for the request.
        :type _content_type: str, Optional
        :param _headers: set to override the headers for a single
                         request; this effectively ignores the headers
                         in the spec for a single request.
        :type _headers: dict, optional
        :param _host_index: set to override the host_index for a single
                            request; this effectively ignores the host_index
                            in the spec for a single request.
        :type _host_index: int, optional
        :return: Returns the result object.
        """  # noqa: E501

        _param = self._get_performance_prediction_serialize(
            performance_prediction_request=performance_prediction_request,
            _request_auth=_request_auth,
            _content_type=_content_type,
            _headers=_headers,
            _host_index=_host_index,
        )

        _response_types_map: Dict[str, Optional[str]] = {
            "200": "PerformancePredictionResponse",
            "400": "Error",
            "422": "Error",
            "500": "Error",
        }
        response_data = self.api_client.call_api(
            *_param, _request_timeout=_request_timeout
        )
        response_data.read()
        return self.api_client.response_deserialize(
            response_data=response_data,
            response_types_map=_response_types_map,
        ).data

    @validate_call
    def get_performance_prediction_with_http_info(
        self,
        performance_prediction_request: PerformancePredictionRequest,
        _request_timeout: Union[
            None,
            Annotated[StrictFloat, Field(gt=0)],
            Tuple[
                Annotated[StrictFloat, Field(gt=0)], Annotated[StrictFloat, Field(gt=0)]
            ],
        ] = None,
        _request_auth: Optional[Dict[StrictStr, Any]] = None,
        _content_type: Optional[StrictStr] = None,
        _headers: Optional[Dict[StrictStr, Any]] = None,
        _host_index: Annotated[StrictInt, Field(ge=0, le=0)] = 0,
    ) -> ApiResponse[PerformancePredictionResponse]:
        """Get runtime performance predictions for a GPU-accelerated workload configuration

        **Get performance predictions for GPU-accelerated training workloads**  This endpoint returns predicted runtime and memory usage (VRAM) for a given training configuration. The predictions are provided per GPU type, allowing you to compare performance across different GPU models.  **Request Parameters:** - `model_name`: The machine learning model to train - `optimizer`: The optimization algorithm (adam or adamw) - `batch_size`: Number of samples processed per training step - `sequence_length`: Length of input sequences (tokens) - `accumulation_steps`: Number of gradient accumulation steps (use 1 for no accumulation)  **Response:** - `vram`: Predicted VRAM usage in GB, keyed by GPU type (e.g., \"A100\", \"H100\", \"RTX4090\") - `runtime`: Predicted runtime per training step in seconds, keyed by GPU type

        :param performance_prediction_request: (required)
        :type performance_prediction_request: PerformancePredictionRequest
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :type _request_timeout: int, tuple(int, int), optional
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the
                              authentication in the spec for a single request.
        :type _request_auth: dict, optional
        :param _content_type: force content-type for the request.
        :type _content_type: str, Optional
        :param _headers: set to override the headers for a single
                         request; this effectively ignores the headers
                         in the spec for a single request.
        :type _headers: dict, optional
        :param _host_index: set to override the host_index for a single
                            request; this effectively ignores the host_index
                            in the spec for a single request.
        :type _host_index: int, optional
        :return: Returns the result object.
        """  # noqa: E501

        _param = self._get_performance_prediction_serialize(
            performance_prediction_request=performance_prediction_request,
            _request_auth=_request_auth,
            _content_type=_content_type,
            _headers=_headers,
            _host_index=_host_index,
        )

        _response_types_map: Dict[str, Optional[str]] = {
            "200": "PerformancePredictionResponse",
            "400": "Error",
            "422": "Error",
            "500": "Error",
        }
        response_data = self.api_client.call_api(
            *_param, _request_timeout=_request_timeout
        )
        response_data.read()
        return self.api_client.response_deserialize(
            response_data=response_data,
            response_types_map=_response_types_map,
        )

    @validate_call
    def get_performance_prediction_without_preload_content(
        self,
        performance_prediction_request: PerformancePredictionRequest,
        _request_timeout: Union[
            None,
            Annotated[StrictFloat, Field(gt=0)],
            Tuple[
                Annotated[StrictFloat, Field(gt=0)], Annotated[StrictFloat, Field(gt=0)]
            ],
        ] = None,
        _request_auth: Optional[Dict[StrictStr, Any]] = None,
        _content_type: Optional[StrictStr] = None,
        _headers: Optional[Dict[StrictStr, Any]] = None,
        _host_index: Annotated[StrictInt, Field(ge=0, le=0)] = 0,
    ) -> RESTResponseType:
        """Get runtime performance predictions for a GPU-accelerated workload configuration

        **Get performance predictions for GPU-accelerated training workloads**  This endpoint returns predicted runtime and memory usage (VRAM) for a given training configuration. The predictions are provided per GPU type, allowing you to compare performance across different GPU models.  **Request Parameters:** - `model_name`: The machine learning model to train - `optimizer`: The optimization algorithm (adam or adamw) - `batch_size`: Number of samples processed per training step - `sequence_length`: Length of input sequences (tokens) - `accumulation_steps`: Number of gradient accumulation steps (use 1 for no accumulation)  **Response:** - `vram`: Predicted VRAM usage in GB, keyed by GPU type (e.g., \"A100\", \"H100\", \"RTX4090\") - `runtime`: Predicted runtime per training step in seconds, keyed by GPU type

        :param performance_prediction_request: (required)
        :type performance_prediction_request: PerformancePredictionRequest
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :type _request_timeout: int, tuple(int, int), optional
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the
                              authentication in the spec for a single request.
        :type _request_auth: dict, optional
        :param _content_type: force content-type for the request.
        :type _content_type: str, Optional
        :param _headers: set to override the headers for a single
                         request; this effectively ignores the headers
                         in the spec for a single request.
        :type _headers: dict, optional
        :param _host_index: set to override the host_index for a single
                            request; this effectively ignores the host_index
                            in the spec for a single request.
        :type _host_index: int, optional
        :return: Returns the result object.
        """  # noqa: E501

        _param = self._get_performance_prediction_serialize(
            performance_prediction_request=performance_prediction_request,
            _request_auth=_request_auth,
            _content_type=_content_type,
            _headers=_headers,
            _host_index=_host_index,
        )

        _response_types_map: Dict[str, Optional[str]] = {
            "200": "PerformancePredictionResponse",
            "400": "Error",
            "422": "Error",
            "500": "Error",
        }
        response_data = self.api_client.call_api(
            *_param, _request_timeout=_request_timeout
        )
        return response_data.response

    def _get_performance_prediction_serialize(
        self,
        performance_prediction_request,
        _request_auth,
        _content_type,
        _headers,
        _host_index,
    ) -> RequestSerialized:

        _host = None

        _collection_formats: Dict[str, str] = {}

        _path_params: Dict[str, str] = {}
        _query_params: List[Tuple[str, str]] = []
        _header_params: Dict[str, Optional[str]] = _headers or {}
        _form_params: List[Tuple[str, str]] = []
        _files: Dict[
            str, Union[str, bytes, List[str], List[bytes], List[Tuple[str, bytes]]]
        ] = {}
        _body_params: Optional[bytes] = None

        # process the path parameters
        # process the query parameters
        # process the header parameters
        # process the form parameters
        # process the body parameter
        if performance_prediction_request is not None:
            _body_params = performance_prediction_request

        # set the HTTP header `Accept`
        if "Accept" not in _header_params:
            _header_params["Accept"] = self.api_client.select_header_accept(
                ["application/json", "application/problem+json"]
            )

        # set the HTTP header `Content-Type`
        if _content_type:
            _header_params["Content-Type"] = _content_type
        else:
            _default_content_type = self.api_client.select_header_content_type(
                ["application/json"]
            )
            if _default_content_type is not None:
                _header_params["Content-Type"] = _default_content_type

        # authentication setting
        _auth_settings: List[str] = ["OAuth2"]

        return self.api_client.param_serialize(
            method="POST",
            resource_path="/performance-prediction",
            path_params=_path_params,
            query_params=_query_params,
            header_params=_header_params,
            body=_body_params,
            post_params=_form_params,
            files=_files,
            auth_settings=_auth_settings,
            collection_formats=_collection_formats,
            _host=_host,
            _request_auth=_request_auth,
        )
